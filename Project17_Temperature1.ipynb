{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=pd.read_csv('E:/Bias_correction_ucl.csv',parse_dates=['Date'])\n",
    "df_temp=pd.DataFrame(df_temp)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for any missing data\n",
    "sns.heatmap(df_temp.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see there are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['LDAPS_PPT2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['LDAPS_CC1'].replace(float(0.000000) ,df_temp['LDAPS_CC1'].mean(),inplace=True)\n",
    "df_temp['LDAPS_CC2'].replace(float(0.000000) ,df_temp['LDAPS_CC2'].mean(),inplace=True)\n",
    "df_temp['LDAPS_CC3'].replace(float(0.000000) ,df_temp['LDAPS_CC3'].mean(),inplace=True)\n",
    "df_temp['LDAPS_CC4'].replace(float(0.000000) ,df_temp['LDAPS_CC4'].mean(),inplace=True)\n",
    "df_temp['LDAPS_PPT1'].replace(float(0.000000) ,df_temp['LDAPS_PPT1'].mean(),inplace=True)\n",
    "df_temp['LDAPS_PPT2'].replace(float(0.000000) ,df_temp['LDAPS_PPT2'].mean(),inplace=True)\n",
    "df_temp['LDAPS_PPT3'].replace(float(0.000000) ,df_temp['LDAPS_PPT3'].mean(),inplace=True)\n",
    "df_temp['LDAPS_PPT4'].replace(float(0.000000) ,df_temp['LDAPS_PPT4'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data types\n",
    "df_temp.dtypes\n",
    "#We can see the attributes are in numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the basic info about the attributes and their counts\n",
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the maximum and minimum values of each attribute and their percentiles\n",
    "df_temp.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean>Median(50 Percentile) LDAPS_LH,DEM,Slope: Left skewed Distribution\n",
    "Mean<edian(50 Percentile)  Solar radiation: Right skewed Distribution\n",
    "Other attributes have normal distribution as mean is almost equal to median\n",
    "\n",
    "Difference between 75 Percentile and max is high(Higher than std dev) in Present_Tmin,LDAPS_RHmin,LDAPS_Tmax_lapse,\n",
    "LDAPS_Tmin_lapse,LDAPS_WS,LDAPS_LH,LDAPS_PPT1,LDAPS_PPT2,LDAPS_PPT3,LDAPS_PPT4,DEM,Slope,Next_Tmax,Next_Tmin\n",
    "So these attributes seem to have outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin',\n",
    "       'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS',\n",
    "       'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4',\n",
    "       'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'lat', 'lon',\n",
    "       'DEM', 'Slope', 'Solar radiation', 'Next_Tmax', 'Next_Tmin']:\n",
    "    plt.boxplot(df_temp[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'Present_Tmax','Present_Tmin','LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS',\n",
    "'LDAPS_LH','DEM', 'Slope', 'Solar radiation', 'Next_Tmax', 'Next_Tmin' have ouliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin',\n",
    "       'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS',\n",
    "       'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4',\n",
    "       'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'lat', 'lon',\n",
    "       'DEM', 'Slope', 'Solar radiation', 'Next_Tmax', 'Next_Tmin']:\n",
    "    sns.violinplot(x=i,data=df_temp)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the distribution of the data\n",
    "for i in ['Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin',\n",
    "       'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS',\n",
    "       'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4',\n",
    "       'DEM', 'Slope', 'Solar radiation', 'Next_Tmax', 'Next_Tmin']:\n",
    "    sns.distplot(df_temp[i],bins='auto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'LDAPS_WS','LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4' have left skewed distributiom\n",
    "'Solar radiation', 'Next_Tmax', 'Next_Tmin' have right skewed distribution\n",
    "'LDAPS_Tmin_lapse' has normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin',\n",
    "       'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS',\n",
    "       'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4',\n",
    "       'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'lat', 'lon',\n",
    "       'DEM', 'Slope', 'Solar radiation'] :\n",
    "    sns.swarmplot(df_temp['Next_Tmax'],df_temp[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin',\n",
    "       'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS',\n",
    "       'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4',\n",
    "       'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'lat', 'lon',\n",
    "       'DEM', 'Slope', 'Solar radiation'] :\n",
    "    sns.swarmplot(df_temp['Next_Tmin'],df_temp[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the correlation between the attributes\n",
    "df_temp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,12))\n",
    "sns.heatmap(df_temp.corr(),cmap='coolwarm',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'Present_Tmax', 'Present_Tmin', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse' have high positive correlation with \n",
    "both 'Next_Tmax' & 'Next_Tmin'\n",
    "\n",
    "'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4' are highly positively correlated to each other\n",
    "'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4' have high positive correlation among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.drop(['station', 'Date','lat', 'lon'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cheking the skewness of data\n",
    "df_temp.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing skewness using log transform\n",
    "for col in df_temp.columns:\n",
    "    if df_temp.skew().loc[col]>0.55:\n",
    "        df_temp[col]=np.log1p(df_temp[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.skew()\n",
    "#reduced skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers using zscore\n",
    "from scipy.stats import zscore\n",
    "zscore=np.abs(zscore(df_temp[['Slope','LDAPS_WS']])) #\n",
    "print(zscore)\n",
    "print(np.where(zscore>3))\n",
    "df_temp_new=df_temp[(zscore<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before removing outliers:',df_temp.shape)\n",
    "print('After removing outliers:',df_temp_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating into input and output variables\n",
    "df_x=df_temp_new.drop(columns=['Next_Tmax', 'Next_Tmin'])\n",
    "y=pd.DataFrame(df_temp_new['Next_Tmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(df_x)\n",
    "x=pd.DataFrame(x,columns=df_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(['LDAPS_LH'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def maxr2_score(regr,x,y):\n",
    "    max_r_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred=regr.predict(x_test)\n",
    "        r2_scr=r2_score(y_test,y_pred)\n",
    "        print(\"r2 score corresponding to\",r_state,\"is\",r2_scr)\n",
    "        if r2_scr>max_r_score:\n",
    "            max_r_score=r2_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max r2 score corresponding to\",final_r_state,\"is\",max_r_score)    \n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LinearRegression and checking maxr2 score corresponding to different random states\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg=LinearRegression()\n",
    "r_state=maxr2_score(lreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neighbors={'n_neighbors':range(1,26)}\n",
    "knr=KNeighborsRegressor()\n",
    "gknr=GridSearchCV(knr,neighbors,cv=10)\n",
    "gknr.fit(x,y)\n",
    "gknr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using KNN regression and checking max r2 score corresponding to different random states\n",
    "knr=KNeighborsRegressor(n_neighbors=25)\n",
    "r_state=maxr2_score(knr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the mean r2 score of both Linear Regression Model and KNN Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean r2 score for Linear Regression:',cross_val_score(lreg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Linear Regression:',cross_val_score(lreg,x,y,cv=5,scoring='r2').std())\n",
    "print()\n",
    "print(\"Mean r2 score for KNN Regression:\",cross_val_score(knr,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for KNN Regression:',cross_val_score(knr,x,y,cv=5,scoring='r2').std())\n",
    "#Based on below output Linear Regression is performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking lasso Regression and finding best value for alpha\n",
    "from sklearn.linear_model import Lasso\n",
    "lsreg=Lasso()\n",
    "parameters={\"alpha\":[0.0001,0.001,0.01,0.1,1]}\n",
    "clf=GridSearchCV(lsreg,parameters,cv=10)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking max r2 score when we use Lasso\n",
    "lsreg=Lasso(alpha=0.01)\n",
    "r_state=maxr2_score(lsreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cross val score with lasso\n",
    "print(\"Mean r2 score for Lasso Regression:\",cross_val_score(lsreg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Lasso Regression:',cross_val_score(lsreg,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Ridge regression and finding best value for alpha\n",
    "from sklearn.linear_model import Ridge\n",
    "rdreg=Ridge()\n",
    "parameters={\"alpha\":[0.001,0.01,0.1,1]}\n",
    "clf=GridSearchCV(rdreg,parameters,cv=10)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking max r2 score when we use Ridge\n",
    "rdreg=Ridge(alpha=1)\n",
    "r_state=maxr2_score(rdreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cross val score with Ridge\n",
    "print(\"Mean r2 score for Ridge Regression:\",cross_val_score(rdreg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Ridge Regression:',cross_val_score(rdreg,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to use Gradient Boosting Technique\n",
    "#For getting best set of parameters, using GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr=GradientBoostingRegressor()\n",
    "parameters={'learning_rate':[0.0001,0.001,0.01,0.1,1],'n_estimators':[50,100,150,200,250,300,350,400,450,500]}\n",
    "clf=GridSearchCV(gbr,parameters,cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cross val score to check the mean r2 score and standard deviation\n",
    "gbr=GradientBoostingRegressor(learning_rate=0.1,n_estimators=100)\n",
    "print(\"Mean r2 score for Gradient Boosting Regression:\",cross_val_score(gbr,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Gradient Boosting Regression:',cross_val_score(gbr,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking maximum r2 score corresponding to GradientBoostingRegressor\n",
    "r_state=maxr2_score(gbr,x,y)gbr=GradientBoostingRegressor(learning_rate=0.1,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Ada Boost regression algorithm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "ada_reg=AdaBoostRegressor()\n",
    "parameters={'learning_rate':[0.0001,0.001,0.01,0.1,1],'n_estimators':[50,100,150,200,250,300,350,400,450,500],'base_estimator':[lreg,lsreg,DecisionTreeRegressor()]}\n",
    "clf=GridSearchCV(ada_reg,parameters,cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg=AdaBoostRegressor(base_estimator=Lasso(),learning_rate=0.0001,n_estimators=50)\n",
    "print(\"Mean r2 score for Ada Boost Regression:\",cross_val_score(ada_reg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Ada Boost Regression:',cross_val_score(ada_reg,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking maximum r2 score corresponding to Ada Boost\n",
    "r_state=maxr2_score(ada_reg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(),learning_rate=0.0001,n_estimators=50)\n",
    "print(\"Mean r2 score for Ada Boost Regression:\",cross_val_score(ada_reg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Ada Boost Regression:',cross_val_score(ada_reg,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking maximum r2 score corresponding to Ada Boost\n",
    "r_state=maxr2_score(ada_reg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2 score for AdaBoostRegressor is .91 which is higher than Gradient Boost r2 score .85\n",
    "#But cross val score of Gradient Boost is .70 higher than Adaboost .66\n",
    "#Differnce between cross val score and r2 score is much high .20 in ada boost\n",
    "#So of tried all methods we tried and till now GradientBoostingRegressor  is the best option \n",
    "#Random state corresponding to highest r2 score is 61\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=61,test_size=0.20)\n",
    "gbr=GradientBoostingRegressor(learning_rate=0.1,n_estimators=100)\n",
    "gbr.fit(x_train,y_train)\n",
    "y_pred=gbr.predict(x_test)\n",
    "print(\"Mean r2 score for  GradientBoostingRegressor:\",cross_val_score(gbr,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for GradientBoostingRegressor:',cross_val_score(gbr,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding RMSE and r2 score using sklearn.metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"RMSE is:\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"r2 score is:\",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the modelas a pickle in a file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gbr,\"Project17_Temperature.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating into input and output variables\n",
    "df_x=df_temp_new.drop(columns=['Next_Tmax', 'Next_Tmin'])\n",
    "y=pd.DataFrame(df_temp_new['Next_Tmin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(df_x)\n",
    "x=pd.DataFrame(x,columns=df_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(['LDAPS_LH'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def maxr2_score(regr,x,y):\n",
    "    max_r_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred=regr.predict(x_test)\n",
    "        r2_scr=r2_score(y_test,y_pred)\n",
    "        print(\"r2 score corresponding to\",r_state,\"is\",r2_scr)\n",
    "        if r2_scr>max_r_score:\n",
    "            max_r_score=r2_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max r2 score corresponding to\",final_r_state,\"is\",max_r_score)    \n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LinearRegression and checking maxr2 score corresponding to different random states\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg=LinearRegression()\n",
    "r_state=maxr2_score(lreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neighbors={'n_neighbors':range(1,26)}\n",
    "knr=KNeighborsRegressor()\n",
    "gknr=GridSearchCV(knr,neighbors,cv=10)\n",
    "gknr.fit(x,y)\n",
    "gknr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using KNN regression and checking max r2 score corresponding to different random states\n",
    "knr=KNeighborsRegressor(n_neighbors=25)\n",
    "r_state=maxr2_score(knr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the mean r2 score of both Linear Regression Model and KNN Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean r2 score for Linear Regression:',cross_val_score(lreg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Linear Regression:',cross_val_score(lreg,x,y,cv=5,scoring='r2').std())\n",
    "print()\n",
    "print(\"Mean r2 score for KNN Regression:\",cross_val_score(knr,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for KNN Regression:',cross_val_score(knr,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking lasso Regression and finding best value for alpha\n",
    "from sklearn.linear_model import Lasso\n",
    "lsreg=Lasso()\n",
    "parameters={\"alpha\":[0.0001,0.001,0.01,0.1,1]}\n",
    "clf=GridSearchCV(lsreg,parameters,cv=10)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking max r2 score when we use Lasso\n",
    "lsreg=Lasso(alpha=0.01)\n",
    "r_state=maxr2_score(lsreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cross val score with lasso\n",
    "print(\"Mean r2 score for Lasso Regression:\",cross_val_score(lsreg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Lasso Regression:',cross_val_score(lsreg,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Ridge regression and finding best value for alpha\n",
    "from sklearn.linear_model import Ridge\n",
    "rdreg=Ridge()\n",
    "parameters={\"alpha\":[0.001,0.01,0.1,1]}\n",
    "clf=GridSearchCV(rdreg,parameters,cv=10)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking max r2 score when we use Ridge\n",
    "rdreg=Ridge(alpha=1)\n",
    "r_state=maxr2_score(rdreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cross val score with Ridge\n",
    "print(\"Mean r2 score for Ridge Regression:\",cross_val_score(rdreg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Ridge Regression:',cross_val_score(rdreg,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to use Gradient Boosting Technique\n",
    "#For getting best set of parameters, using GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr=GradientBoostingRegressor()\n",
    "parameters={'learning_rate':[0.0001,0.001,0.01,0.1,1],'n_estimators':[50,100,150,200,250,300,350,400,450,500]}\n",
    "clf=GridSearchCV(gbr,parameters,cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cross val score to check the mean r2 score and standard deviation\n",
    "gbr=GradientBoostingRegressor(learning_rate=0.1,n_estimators=100)\n",
    "print(\"Mean r2 score for Gradient Boosting Regression:\",cross_val_score(gbr,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Gradient Boosting Regression:',cross_val_score(gbr,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking maximum r2 score corresponding to GradientBoostingRegressor\n",
    "r_state=maxr2_score(gbr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Ada Boost regression algorithm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "ada_reg=AdaBoostRegressor()\n",
    "parameters={'learning_rate':[0.0001,0.001,0.01,0.1,1],'n_estimators':[50,100,150,200,250,300,350,400,450,500],'base_estimator':[lreg,lsreg,DecisionTreeRegressor()]}\n",
    "clf=GridSearchCV(ada_reg,parameters,cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg=AdaBoostRegressor(base_estimator=Lasso(),learning_rate=0.0001,n_estimators=100)\n",
    "print(\"Mean r2 score for Ada Boost Regression:\",cross_val_score(ada_reg,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for Ada Boost Regression:',cross_val_score(ada_reg,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking maximum r2 score corresponding to Ada Boost\n",
    "r_state=maxr2_score(ada_reg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So of tried all methods we tried and till now GradientBoostingRegressor  is the best option \n",
    "#Random state corresponding to highest r2 score is 85\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=85,test_size=0.20)\n",
    "gbr1=GradientBoostingRegressor(learning_rate=0.1,n_estimators=100)\n",
    "gbr1.fit(x_train,y_train)\n",
    "y_pred=gbr1.predict(x_test)\n",
    "print(\"Mean r2 score for  GradientBoostingRegressor:\",cross_val_score(gbr1,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard Deviation in r2 score for GradientBoostingRegressor:',cross_val_score(gbr1,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding RMSE and r2 score using sklearn.metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"RMSE is:\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"r2 score is:\",r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the modelas a pickle in a file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gbr1,\"Project17a_Temperature.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
